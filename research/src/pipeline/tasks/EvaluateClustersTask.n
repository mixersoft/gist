using Nemerle.Collections;
using Nemerle.Utility;
using PipelineMacro;
using Profiling;
using System.IO;
using System;

public class EvaluateClustersTask: ITask
{
	public MapItems(items : list[ITaskItem]) : list[TaskMapping]
	{
		def clusters   = items.Filter(item => item.Path.StartsWith(@"clusters\"));
		def references = items.Filter(item => item.Path.StartsWith(@"clusters-ref\"));

		def references = Hashtable(references.Map(item => (item.Path, item)));

		mutable mappings = [];
		foreach (cluster is ClusterItem in clusters)
		{
			def fileName = Path.GetFileName(cluster.Path);
			match (references.Get(Path.Combine("clusters-ref", fileName)))
			{
			| Some(reference is ClusterItem ) =>
				def path = Path.Combine("eval", fileName);
				mappings ::= TaskMapping(this, [ cluster, reference ], [ ClusterEvaluationItem(path) ]);
			| _ => ()
			}
		}
		mappings;
	}

	[ Profile(Recursive) ]
	private Compute
		( [InItem]  autoClusters : ClusterItem
		, [InItem]  refClusters  : ClusterItem
		, [OutItem] result       : ClusterEvaluationItem
		) : void
	{
		def MakeHash(c)
		{
			c.Fold(0, (c, hash) => c.Fold(hash, (id, hash) => hash ^ id.GetHashCode()))
		}

		/// <summary>
		/// Remove the last reference cluster and all items containined in it.
		/// This cluster is reserved for unsorted items.
		/// </summary>
		def PrepareClusters(autoClusters, mutable refClusters)
		{
			def set = Set(refClusters[refClusters.Length - 1]);
			Array.Resize(ref refClusters, refClusters.Length - 1);
			( autoClusters
				.MapToArray(clusters => clusters.FilterToArray(id => !set.Contains(id)))
				.FilterToArray(clusters => clusters.Length > 0)
			, refClusters
			);
		}

		/// <summary>
		/// Number of discrepancies between two partitions of a set.
		/// Similar to <a src="http://en.wikipedia.org/wiki/Rand_index">Rand index</a>.
		/// </summary>
		def EvaluateClusters(l1, l2) : double
		{
			def PairsCount(n)
			{
				n * (n - 1) / 2
			}
			def GetContingencyTableSum(l1, l2)
			{
				mutable sum = 0;
				foreach (x in l1 with i)
				foreach (y in l2 with j)
					sum += PairsCount(x.Intersect(y).Count);
				sum;
			}
			def GetMarginalSum(l)
			{
				l.Fold(0, (x, sum) => sum + PairsCount(x.Count))
			}
			def TotalPairsCount(l)
			{
				PairsCount(l.Fold(0, (x, sum) => sum + x.Count))
			}

			def l1 = l1.Map(Set);
			def l2 = l2.Map(Set);

			def ab : int = GetContingencyTableSum(l1, l2);
			def a  : int = GetMarginalSum(l1);
			def b  : int = GetMarginalSum(l2);
			def n2 : int = TotalPairsCount(l1);

			// Adjusted rand index:
			// (Index - ExpectedIndex) / (MaxIndex - ExpectedIndex)
			unchecked (n2 * ab - a * b) / (0.5 * n2 * (a + b) - a * b);
		}

		def autoClusters = autoClusters.Clusters;
		def refClusters  = refClusters.Clusters;

		when (MakeHash(autoClusters) != MakeHash(refClusters))
			throw Exception("Cannot compare clusters of different items.");

		result.Value = EvaluateClusters(PrepareClusters(autoClusters, refClusters));
	}
}
