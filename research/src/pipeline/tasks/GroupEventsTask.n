using Nemerle.Collections;
using PipelineMacro;
using System.Collections.Generic;
using System.Math;
using System;

public enum EventGroupMethod
{
| Fixed
| Adaptive
}

class GroupEventsTask : ITask
{
	public MapItems(items : list[ITaskItem]) : list[TaskMapping]
	{
		mutable mappings = [];
		foreach (item is JsonItem in items)
			mappings ::= TaskMapping(this, [ item ], [ EventGroupItem(item.Name) ]);
		mappings;
	}

	private Compute
		( [InItem]  json   : JsonItem
		, [OutItem] events : EventGroupItem
		, kdeWindow        : double
		, msIterationCount : int
		, msKernel         : MeanShiftKernel
		, eventSpacing     : double
		, dayQuota         : int
		, eventGroupMethod : EventGroupMethod
		) : void
	{
		def AddNoiseToSpans(spans, noise, times)
		{
			// prepare data structures for searching span endings
			def oldEndings = array(spans.Length * 2);
			foreach ((s, f) in spans with i)
			{
				oldEndings[i + i + 0] = s.Ticks :> double;
				oldEndings[i + i + 1] = f.Ticks :> double;
			}
			def newEndings = oldEndings.Clone() :> array[double];

			// match noise items to nearest endings
			def GetNearest(arr, x)
			{
				mutable minD = double.MaxValue;
				mutable minI = 0;
				foreach (y in arr with i)
				{
					def d = Abs(x - y);
					when (d < minD)
					{
						minD = d;
						minI = i;
					}
				}
				minI;
			}
			foreach (i in noise)
			{
				def t = times[i];
				def j = GetNearest(oldEndings, t);
				newEndings[j] =
					if (j % 2 == 0) Min(newEndings[j], t) // start
					else            Max(newEndings[j], t) // finish
			}

			// create new spans
			def ToTime(t)
			{
				DateTime(t :> long)
			}
			def spans = array(spans.Length);
			for (mutable i = 0; i != spans.Length; ++i)
				spans[i] = (ToTime(newEndings[i + i]), ToTime(newEndings[i + i + 1]));
			spans;
		}
		// returns the list of indices at which new groups begin
		// assumes the data is sorted in increasing order
		def Aggregate(data, step)
		{
			def events = List();
			when (data.Length > 0)
			{
				mutable prev = data[0];
				for (mutable i = 1; i != data.Length; ++i)
				{
					when (data[i] - prev > step)
						events.Add(i);
					prev = data[i];
				}
				events.Add(data.Length);
			}
			events.ToArray();
		}
		def AverageGroup(data, separators)
		{
			def means = array(separators.Length);
			mutable i = 0;
			foreach (separator in separators with j)
			{
				mutable acc, n;
				while (i != separator)
					(acc, n, i) = (acc + data[i], n + 1, i + 1);
				means[j] = acc / n;
			}
			means;
		}
		def EventToSpan(indices, times)
		{
			def ToTime(i)
			{
				DateTime(times[indices[i]] :> long)
			}
			(ToTime(0), ToTime(indices.Length - 1))
		}
		def FilterData(indices, noise)
		{
			def result = List();
			foreach (i when !noise.Contains(i) in indices)
				result.Add(i);
			result.ToArray();
		}
		def FindEventsFixed(indices, times, spacing)
		{
			def IsBoundary(i)
			{
				def curr = times[indices[i]];
				def next = times[indices[i+1]];
				next - curr > spacing;
			}
			def events = List();
			def e = List();
			for (mutable i = 0; i != indices.Length; ++i)
			{
				e.Add(indices[i]);
				when (i + 1 == indices.Length || IsBoundary(i))
				{
					events.Add(e.ToArray());
					e.Clear();
				}
			}
			events.ToArray();
		}
		def FindEventsAdaptive(indices, times, threshold)
		{
			// compare current gap with the average of nearby gaps
			// log(g_i) ≥ K + Σ(log(g_j), j = i - wnd … i + wnd) / (2·d + 1)
			//
			// J. Platt, M. Czerwinski, and B. Field, “Phototoc: Automatic clustering for browsing
			// personal photographs,” Information, Commun.  Signal Process.  2003 Fourth Pacific
			// Rim Conf. Multimedia. Proc. 2003 Jt. Conf. Fourth Int. Conf., 2003.
			def IsBoundary(i)
			{
				mutable total = 0.0;
				mutable count = 0;

				def wnd = 4;
				for (mutable j = i - wnd; j <= i + wnd; ++j)
				{
					when (j >= 0 && j + 1 < indices.Length)
					{
						def curr = times[indices[j]];
						def next = times[indices[j+1]];
						when (next != curr)
						{
							total += Log(next - curr);
							++count;
						}
					}
				}

				def curr = times[indices[i]];
				def next = times[indices[i+1]];

				next != curr && Log(next - curr) > threshold + total / count;
			}

			def events = List();
			def e = List();
			for (mutable i = 0; i != indices.Length; ++i)
			{
				e.Add(indices[i]);
				when (i + 1 == indices.Length || IsBoundary(i))
				{
					events.Add(e.ToArray());
					e.Clear();
				}
			}
			events.ToArray();
		}
		def FindNoise(separators)
		{
			mutable noiseData   = Set();
			mutable noiseGroups = Set();
			mutable prev = 0;
			foreach (separator in separators with i)
			{
				when (separator - prev < dayQuota)
				{
					noiseData   = noiseData.AddList($[prev .. separator - 1]);
					noiseGroups = noiseGroups.Add(i);
				}
				prev = separator;
			}
			(noiseData, noiseGroups);
		}
		def MeanShift(data, window)
		{
			def hFactor = 1.0 / (window * window);
			def n       = data.Length;

			def GetRange(i, support)
			{
				def (lo, hi) = (data[i] - support, data[i] + support);
				mutable min = i - 1;
				while (min >= 0 && data[min] >= lo)
					--min;
				++min;
				mutable max = i + 1;
				while (max < n && data[max] <= hi)
					++max;
				(min, max);
			}

			def modes = array(n);
			data.CopyTo(modes, 0);

			repeat (msIterationCount)
			{
				for (mutable i = 0; i != n; ++i)
				{
					mutable xi    = modes[i];
					mutable mode  = 0.0;
					mutable total = 0.0;
					match (msKernel)
					{
					| MeanShiftKernel.Epanechnikov =>
						def (minJ, maxJ) = GetRange(i, window);
						for (mutable j = minJ; j != maxJ; ++j)
						{
							def xj = data[j];
							def w = 1.0 - hFactor * (xi - xj) * (xi - xj);
							when (w > 0.0)
							{
								total += w;
								mode += xj * w;
							}
						}
					| MeanShiftKernel.Gaussian =>
						def (minJ, maxJ) = GetRange(i, window * 5.0);
						for (mutable j = minJ; j != maxJ; ++j)
						{
							def xj = data[j];
							def w = Exp(-0.5 * hFactor * (xi - xj) * (xi - xj));
							total += w;
							mode += xj * w;
						}
					}
					modes[i] = mode / total;
				}
			}
			modes;
		}

		def ticksPerDay  = 24 * 60 * 60 * 10_000_000;
		def window       = kdeWindow * ticksPerDay;
		def groupSpacing = 0.1 * window;

		// retrieve a sorted array of photo times
		def times = json.Photos.MapToArray(p => p.DateTaken.Ticks :> double);
		Array.Sort(times);

		// use mean shift to group events by day
		def modes = MeanShift(times, window);

		events.DayGroups = Aggregate(modes, groupSpacing);
		events.DayTimes  = AverageGroup(modes, events.DayGroups);

		// determine which days to consider as noise
		def (noiseTimes, noiseDays) = FindNoise(events.DayGroups);
		events.NoiseDays = noiseDays;

		def filteredTimes = FilterData($[0..times.Length-1].ToArray(), noiseTimes);

		// group non-noise photos
		def groups = 
			match (eventGroupMethod)
			{
			| Fixed    => FindEventsFixed    (filteredTimes, times, eventSpacing * ticksPerDay)
			| Adaptive => FindEventsAdaptive (filteredTimes, times, eventSpacing)
			}
		events.Groups = AddNoiseToSpans(groups.Map(EventToSpan(_, times)), noiseTimes, times);
	}
}
