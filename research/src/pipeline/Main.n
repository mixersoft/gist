using Nemerle.Collections;
using Nemerle.Text;
using Nemerle.Utility;
using Newtonsoft.Json.Linq;
using PipelineMacro;
using Profiling;
using System.IO;
using System.Math;
using System.Net;
using System;

using SCG = System.Collections.Generic;

[assembly: ProfSetup(Disabled) ]
[assembly: PipelineSetup ]

module Main
{
	[ ProfDump ]
	private PrintProfileInfo() : void
	{
	}

	private Run() : void
	{
		def parameters = Parameters();
		parameters.Load("parameters.txt");
		_ = TaskManager
			( tasks =
				// source Json and image data
				[ LoadJsonDataTask()
				, DownloadDataTask()
				, CreateThumbnailsTask()

				// dominant colour detection
				, FindDominantColorTask()
				, CreateDominantColorHtmlTask()

				// descriptor extraction
				, ExtractDescriptorsTask()

				// image clustering
				, ClusterDataTask()
				, CreateClusterHtmlTask()
				, CreateClusterJsonTask()
				, LoadReferenceClustersTask()
				, EvaluateClustersTask()
				, CreateSequenceHtmlTask()

				// duplicate detection
				, FindDuplicatesTask()
				, CreateDuplicatesHtmlTask()
				, LoadReferenceDuplicatesTask()
				, EvaluateDuplicatesTask()
				, CreateDuplicateEvalHtmlTask()

				// face detection
				, DetectFacesTask()
				, CreateFacesPreviewsTask()
				, LoadReferenceFacesTask()
				, EvaluateFacesTask()

				// image hashing
				, SampleImagesTask()
				, ExtractHashTask()
				, GroupShotsTask()
				, EvaluateImageHashUniquenessTask()
				, EvaluateImageHashConsistencyTask()

				// timeline alignment
				, GraphTimelineTask()
				, SplitTimelineTask()
				, AlignTimelinesTask()

				// event grouping
				, LoadReferenceEventsTask()
				, GroupEventsTask()
				, GraphEventsTask()
				, CreateEventGroupJsonTask()
				]
			, persistData     = true
			, displayProgress = true
			).Compute(parameters);
		PrintProfileInfo();
	}

	private RunColorOptimization() : void
	{
		def parameters = Parameters();
		parameters.Load("parameters.txt");

		def taskManager = TaskManager
			( tasks =
				[ LoadJsonDataTask()
				, DownloadDataTask()
				, ExtractDescriptorsTask()
				, ClusterDataTask()
				, LoadReferenceClustersTask()
				, EvaluateClustersTask()
				]
			, persistData     = false
			, displayProgress = false
			);

		def taskPath = @"eval\venice.txt";
		def task =
			match (taskManager.Items.Find(item : ITaskItem => item.Path == taskPath))
			{
			| Some(item is ClusterEvaluationItem) => item
			| _                                   => throw Exception($"'$taskPath' not found.")
			}

		def outFile = File.CreateText("color test.txt");
		outFile.WriteLine("threshold\tcolor\tvalue");

		def Rand = Random(0).NextDouble;
		def LinRand(min, max) { min + Rand() * (max - min) }
		def LogRand(min, max) { Exp(Log(min) + Rand() * (Log(max) - Log(min))) }

		for (mutable i = 0;; ++i)
		{
			parameters.ClusteringThreshold = LinRand(0.2, 0.6);
			parameters.ColorWeight         = LogRand(0.001, 1.0);

			taskManager.DiscardItemData(@"descriptors\venice");
			taskManager.Compute(parameters);

			when (i % 10 == 0)
				Console.WriteLine();
			Console.Write('.');

			outFile.WriteLine
				( "{0}\t{1}\t{2}"
				, parameters.ClusteringThreshold
				, parameters.ColorWeight
				, task.Value
				);
			outFile.Flush();
		}
	}

	private RunDuplicateOptimization() : void
	{
		def parameters = Parameters();
		parameters.Load("parameters.txt");

		def taskManager = TaskManager
			( tasks =
				[ LoadJsonDataTask()
				, DownloadDataTask()

				, FindDuplicatesTask()
				, LoadReferenceDuplicatesTask()
				, EvaluateDuplicatesTask()
				]
			, persistData     = false
			, displayProgress = false
			);
		def Eval(eval)
		{
			taskManager.DiscardItemData($@"work\Duplicates\$(eval.Name).txt");
			taskManager.Compute(parameters);
			eval.Score;
		}

		foreach (eval is DuplicatesEvaluationItem in taskManager.Items)
		{
			Console.WriteLine(eval.Name);

			foreach (threshold in [0..63])
			{
				parameters.DuplicateThreshold = threshold;

				parameters.DuplicateHash = ImageHash.HashMethod.Mean;
				def meanScore = Eval(eval);

				parameters.DuplicateHash = ImageHash.HashMethod.Median;
				def medianScore = Eval(eval);

				Console.WriteLine("{0,2}: {1} {2}", threshold, meanScore, medianScore);
			}
		}
	}

	private RunFaceOptimization() : void
	{
		def parameters = Parameters();
		parameters.Load("parameters.txt");

		def taskManager = TaskManager
			( tasks =
				[ LoadJsonDataTask()
				, DownloadDataTask()

				, DetectFacesTask()
				, LoadReferenceFacesTask()
				, EvaluateFacesTask()
				]
			, persistData     = false
			, displayProgress = true
			);
		def Eval(eval)
		{
			taskManager.DiscardItemData($@"work\Faces\$(eval.Name).txt");
			taskManager.Compute(parameters);
			eval.Score;
		}

		def sets = [ "bali", "venice" ];

		foreach (eval is FacesEvaluationItem when sets.Contains(eval.Name) in taskManager.Items)
			Console.WriteLine("{0}: {1}", eval.Name, Eval(eval));
	}

	public RunImageHashOptimization() : void
	{
		Console.WriteLine("Image hash optimization:");

		def parameters = Parameters();
		parameters.Load("parameters.txt");

		def taskManager = TaskManager
			( tasks =
				[ LoadJsonDataTask()
				, DownloadDataTask()
				, SampleImagesTask()
				, EvaluateImageHashUniquenessTask()
				, EvaluateImageHashConsistencyTask()
				]
			, persistData     = false
			, displayProgress = false
			);

		def uniquenessItems =
			[ @"eval\paris hash uniqueness.html"
			, @"eval\saturday hash uniqueness.html"
			].Map
			( path => taskManager.Items.TypedFind
				( item : ImageHashUniquenessEvaluationItem =>
					item.Path == path
				).Value
			);

		def consistencyItem = taskManager.Items.TypedFind
			( item : ImageHashConsistencyEvaluationItem =>
				item.Path == @"eval\image sample.txt"
			).Value;

		def itemsToDiscard = consistencyItem :: uniquenessItems.Map(_ : ITaskItem);

		using (writer = File.CreateText("image hash.txt"))
		{
			writer.Write
				( "size\tbpp\t{0}"
				, Path.GetFileNameWithoutExtension(consistencyItem.Path)
				);
			foreach (item in uniquenessItems)
				writer.Write("\t" + Path.GetFileNameWithoutExtension(item.Path));

			writer.WriteLine();

			foreach (size in [5 .. 15])
			foreach (bpp  in [1 .. 4])
			{
				Console.WriteLine($"size = $size, bpp = $bpp");

				parameters.HashedImageBpp  = bpp;
				parameters.HashedImageSize = size;

				foreach (item in itemsToDiscard)
					taskManager.DiscardItemData(item.Path);
				taskManager.Compute(parameters);

				def CountUnique(l)
				{
					l.Fold(Set(), (x, union) => union.Replace(x)).Count
				}

				writer.Write
					( "{0}\t{1}\t{2}"
					, size
					, bpp
					, consistencyItem.Hashes
						.Map((_, hashes) => CountUnique(hashes))
						.Fold(0, _ + _) / (consistencyItem.Hashes.Length : double)
					);

				foreach (item in uniquenessItems)
				{
					def sum = item.Conflicts.Map(_.Length).Fold(0, _ + _);
					writer.Write("\t{0}", sum);
				}

				writer.WriteLine();
				writer.Flush();
			}
		}


		/*
		def uniquenessTaskPath = $@"eval\\$dataSet hash uniqueness.txt";
		def uniquenessTask =
			match (taskManager.Items.Find(item => item.Path == taskPath))
			{
			| Some(item is ImageHashUniquenessEvaluationItem) => item
			| _ => throw Exception($"'$uniquenessTaskPath' not found.")
			}

		def consistencyTaskPath =  @"eval\image sample.txt";
		def uniquenessTask =
			match (taskManager.Items.Find(item => item.Path == taskPath))
			{
			| Some(item is ImageHashUniquenessEvaluationItem) => item
			| _ => throw Exception($"'$consistencyTaskPath' not found.")
			}

		def sizes = $[4,6..12];
		def bpps  = $[1..6];

		def Run(w, h)
		{
			def Run(threshold)
			{
				parameters.ClusteringThreshold = threshold;

				taskManager.DiscardItemData($@"clusters\$dataSet.txt");
				taskManager.Compute(parameters);

				Console.WriteLine($"$(w)x$(h)\t$threshold\t$(task.Value)");
			}

			parameters.ImageSize = (w, h);

			taskManager.DiscardItemData($@"descriptors\$dataSet");

			def Lerp(step : int)
			{
				min + (max - min) * step / count
			}
			$[0 .. count].Map(Lerp).Iter(Run);
		}

		Console.WriteLine("Image size optimization:");
		[ (90, 90), (120, 120), (256, 256) ].Iter(Run);
		*/
	}

	private RunImageSizeOptimization() : void
	{
		def parameters = Parameters();
		parameters.Load("parameters.txt");

		def taskManager = TaskManager
			( tasks =
				[ LoadJsonDataTask()
				, DownloadDataTask()
				, ExtractDescriptorsTask()
				, ClusterDataTask()
				, LoadReferenceClustersTask()
				, EvaluateClustersTask()
				]
			, persistData     = false
			, displayProgress = false
			);

		def dataSet = "peter-alice";

		def taskPath = $@"eval\$dataSet.txt";
		def task =
			match (taskManager.Items.Find(item => item.Path == taskPath))
			{
			| Some(item is ClusterEvaluationItem) => item
			| _ => throw Exception($"'$taskPath' not found.")
			}

		def (min, max, count) = (0.1, 0.9, 80);

		def Run(w, h)
		{
			def Run(threshold)
			{
				parameters.ClusteringThreshold = threshold;

				taskManager.DiscardItemData($@"clusters\$dataSet.txt");
				taskManager.Compute(parameters);

				Console.WriteLine($"$(w)x$(h)\t$threshold\t$(task.Value)");
			}

			parameters.ImageSize = (w, h);

			taskManager.DiscardItemData($@"descriptors\$dataSet");

			def Lerp(step : int)
			{
				min + (max - min) * step / count
			}
			$[0 .. count].Map(Lerp).Iter(Run);
		}

		Console.WriteLine("Image size optimization:");
		[ (90, 90), (120, 120), (256, 256) ].Iter(Run);
	}

	private RunJson() : void
	{
		def parameters = Parameters();
		parameters.Load("parameters.txt");
		_ = TaskManager
			( tasks =
				// source Json and image data
				[ LoadJsonDataTask()
				, DownloadDataTask()

				// dominant colour detection
				, FindDominantColorTask()
				, CreateDominantColorHtmlTask()

				// descriptor extraction
				, ExtractDescriptorsTask()

				// image clustering
				, ClusterDataTask()
				, CreateClusterHtmlTask()
				, CreateClusterJsonTask()

				// event grouping
				, GroupEventsTask()
				, CreateEventGroupJsonTask()
				]
			, persistData     = true
			, displayProgress = true
			).Compute(parameters);
	}

	private RunThresholdOptimization(min : double, max : double, count : int) : void
	{
		def parameters = Parameters();
		parameters.Load("parameters.txt");

		def taskManager = TaskManager
			( tasks =
				[ LoadJsonDataTask()
				, DownloadDataTask()
				, ExtractDescriptorsTask()
				, ClusterDataTask()
				, LoadReferenceClustersTask()
				, EvaluateClustersTask()
				]
			, persistData     = false
			, displayProgress = true
			);

		def taskPath = @"eval\peter-alice.txt";
		def task =
			match (taskManager.Items.Find(item : ITaskItem => item.Path == taskPath))
			{
			| Some(item is ClusterEvaluationItem) => item
			| _                                   => throw Exception($"'$taskPath' not found.")
			}

		def Run(threshold)
		{
			parameters.ClusteringThreshold = threshold;

			taskManager.DiscardItemData(@"clusters\peter-alice.txt");
			taskManager.Compute(parameters);

			Console.WriteLine($"$threshold\t$(task.Value)");
		}

		Console.WriteLine("Threshold optimization:");
		def Lerp(step : int)
		{
			min + (max - min) * step / count
		}
		$[0 .. count].Map(Lerp).Iter(Run);
	}

	public Main(args : array[string]) : void
	{
		mutable opts;

		def DisplayHelp()
		{
			Console.WriteLine(Getopt.Usage(opts));
		}

		opts =
			[ Getopt.CliOption.Flag
				( "-json"
				, "Generate JSON output."
				, RunJson
				)
			, Getopt.CliOption.Flag
				( "-optimize-color"
				, "Optimize dominant color component."
				, RunColorOptimization
				)
			, Getopt.CliOption.Flag
				( "-optimize-duplicates"
				, "Optimize duplicate threshold."
				, RunDuplicateOptimization
				)
			, Getopt.CliOption.Flag
				( "-optimize-faces"
				, "Optimize face detection."
				, RunFaceOptimization
				)
			, Getopt.CliOption.Flag
				( "-optimize-image-hash"
				, "Optimize the image hash."
				, RunImageHashOptimization
				)
			, Getopt.CliOption.Flag
				( "-optimize-image-size"
				, "Optimize the image size."
				, RunImageSizeOptimization
				)
			, Getopt.CliOption.String
				( "-optimize-threshold"
				, "Optimize the threshold meta-parameter over the given range: 'min max count'."
				, value =>
					regexp match (value)
					{
					| @"(?<min:double>[^ ]+) (?<max:double>[^ ]+) (?<count:int>[^ ]+)" =>
						RunThresholdOptimization(min, max, count)
					| _ =>
						Console.WriteLine($"Invalid threshold range: '$value'.");
						DisplayHelp()
					}
				)
			, Getopt.CliOption.Flag
				( "-help"
				, [ "-?" ]
				, "Display this message."
				, DisplayHelp
				)
			];

		if (args.Length == 0)
			Run()
		else
			Getopt.Parse(opts);
	}
}
